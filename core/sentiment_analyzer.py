from .models import analysed_news as news
from pandas import DataFrame
from datetime import datetime
from asgiref.sync import async_to_sync
import channels.layers
channel_layer = channels.layers.get_channel_layer()


def sentiment_analyzer():

    logs_Sender_Printer("ğŸ”¥è¼‰å…¥æƒ…ç·’åˆ†ææ¨¡å‹")
    from transformers import BertTokenizer, BertForSequenceClassification

    # ä¸­æ–‡æƒ…ç·’æ¨¡å‹
    model_name = "uer/roberta-base-finetuned-jd-binary-chinese"
    # model_name = "bert-base-chinese"  # å®˜æ–¹ä¸­æ–‡

    # è¼‰å…¥æ¨¡å‹èˆ‡ tokenizer
    model = BertForSequenceClassification.from_pretrained(
        model_name, num_labels=2)
    # è‡ªå‹•é¸æ“‡ GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
    # device = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")
    device = 0
    model.to(device)
    tokenizer = BertTokenizer.from_pretrained(model_name)

    logs_Sender_Printer("ğŸ”¥è¼‰å…¥æƒ…ç·’åˆ†ææ¨¡å‹å®Œæˆï¼")
    got_news_dict: DataFrame = news.db_get_sentiment_DataFrame()
    logs_Sender_Printer(f"â„¹ï¸å·²è®€å–åˆ°{len(got_news_dict)}ç­†æœªåˆ†ææ–°è")
    logs_Sender_Printer(f"â„¹ï¸é–‹å§‹é€²è¡Œæƒ…ç·’åˆ†æ")

    def get_sentiment_proba_from_model(text) -> list:
        """
        åˆ†ææ–‡ç« æƒ…ç·’\n
        åªèƒ½é€éå‰512å­—åˆ†æï¼Œå¤šé¤˜éƒ¨åˆ†æœƒè‡ªå‹•æ’é™¤ã€‚

        Args:
            text (str): æ¬²åˆ†ææ–‡ç« 

        Returns:
            list: [è² é¢æ©Ÿç‡:floatï¼Œæ­£é¢æ©Ÿç‡:float]
        """
        max_length = 512  # æœ€å¤šå­—æ•¸ è‹¥è¶…å‡ºæ¨¡å‹è¨“ç·´æ™‚çš„å­—æ•¸ï¼Œä»¥æ¨¡å‹æœ€å¤§å­—æ•¸ç‚ºä¾æ“š
        # prepare our text into tokenized sequence
        inputs = tokenizer(text, padding=True, truncation=True,
                           max_length=max_length, return_tensors="pt")
        inputs = {k: v.to(device) for k, v in inputs.items()}
        # perform inference to our model
        outputs = model(**inputs)
        # get output probabilities by doing softmax
        probs = outputs[0].softmax(1)

        response = [round(float(probs[0, 0]), 2), round(float(probs[0, 1]), 2)]
        # executing argmax function to get the candidate label
        # return probs.argmax()
        return response

    for idx, row in got_news_dict.iterrows():
        sentiment = get_sentiment_proba_from_model(
            row['content'])
        got_news_dict.at[idx, 'sentiment'] = sentiment  # æ–°å¢æˆ–æ›´æ–° sentiment æ¬„ä½

    # å°‡ DataFrame å¯«å…¥è³‡æ–™åº«
    if news.db_bulk_update_DataFrame(got_news_dict):
        logs_Sender_Printer("âœ…å·²å„²å­˜æƒ…ç·’åˆ†æ")
    else:
        logs_Sender_Printer("â—æƒ…ç·’åˆ†æå„²å­˜å¤±æ•—")


def logs_Sender_Printer(message: str) -> bool:
    """
    å‘asgiä¼ºæœå™¨ç™¼é€WebSocketè¨Šæ¯

    Args:
        message (str): è¦ç™¼é€çš„è¨Šæ¯

    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    try:
        print(message)
        log_message = f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] [sentiment_analyzer] {message}"
        async_to_sync(channel_layer.group_send)(
            "celery_logs", {"type": "log_message", "message": log_message}
        )
        return True
    except Exception as ex:
        print(f"â—core/sentiment_analyzer/logs_sender éŒ¯èª¤: {ex}")
        return False
